{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) White wine ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold,cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequality-white.csv', low_memory=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the response variables(3-7) as binary response variables that is either good or bad\n",
    "\n",
    "#names = ['bad', 'good']\n",
    "#bins = (2, 6.5, 9)\n",
    "\n",
    "#data['quality'] = pd.cut(data['quality'], bins = bins, labels = names)\n",
    "\n",
    "data['quality'] = data['quality'].map({3 : 'bad', 4 :'bad', 5: 'bad',\n",
    "                                      6: 'good', 7: 'good', 8: 'good',\n",
    "                                      9: 'bad'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good    3253\n",
       "bad     1645\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyzing the different values present in the dependent variable(quality column)\n",
    "data['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "5       1\n",
       "6       1\n",
       "7       1\n",
       "8       1\n",
       "9       1\n",
       "10      0\n",
       "11      0\n",
       "12      0\n",
       "13      1\n",
       "14      0\n",
       "15      1\n",
       "16      1\n",
       "17      1\n",
       "18      1\n",
       "19      0\n",
       "20      1\n",
       "21      1\n",
       "22      1\n",
       "23      0\n",
       "24      1\n",
       "25      1\n",
       "26      1\n",
       "27      1\n",
       "28      1\n",
       "29      1\n",
       "       ..\n",
       "4868    1\n",
       "4869    1\n",
       "4870    1\n",
       "4871    1\n",
       "4872    0\n",
       "4873    1\n",
       "4874    1\n",
       "4875    1\n",
       "4876    1\n",
       "4877    0\n",
       "4878    0\n",
       "4879    1\n",
       "4880    1\n",
       "4881    1\n",
       "4882    0\n",
       "4883    1\n",
       "4884    0\n",
       "4885    1\n",
       "4886    1\n",
       "4887    1\n",
       "4888    0\n",
       "4889    1\n",
       "4890    1\n",
       "4891    1\n",
       "4892    0\n",
       "4893    1\n",
       "4894    0\n",
       "4895    1\n",
       "4896    1\n",
       "4897    1\n",
       "Name: quality, Length: 4898, dtype: int32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "data['quality'] = le.fit_transform(data['quality'])\n",
    "data['quality'].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c811745e80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898, 11)\n",
      "(4898,)\n"
     ]
    }
   ],
   "source": [
    "# dividing the dataset into dependent and independent variables\n",
    "\n",
    "x = data.iloc[:,:11]\n",
    "y = data.iloc[:,11]\n",
    "\n",
    "# determining the shape of x and y.\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3673, 11)\n",
      "(3673,)\n",
      "(1225, 11)\n",
      "(1225,)\n"
     ]
    }
   ],
   "source": [
    "# dividing the dataset in training and testing set\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 44)\n",
    "\n",
    "# determining the shapes of training and testing sets\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaling \n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy : 0.9360196025047645\n",
      "testing accuracy : 0.7869387755102041\n"
     ]
    }
   ],
   "source": [
    "# creating the model\n",
    "model = MLPClassifier(hidden_layer_sizes = (100, 100), max_iter = 150)\n",
    "\n",
    "# feeding the training data to the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# calculating the accuracies\n",
    "print(\"training accuracy :\", model.score(x_train, y_train))\n",
    "print(\"testing accuracy :\", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 177\n",
      "Trainable params: 177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3673/3673 [==============================] - 1s 228us/step - loss: 0.6031 - acc: 0.6845\n",
      "Epoch 2/100\n",
      "3673/3673 [==============================] - 1s 139us/step - loss: 0.5127 - acc: 0.7555\n",
      "Epoch 3/100\n",
      "3673/3673 [==============================] - 1s 206us/step - loss: 0.5026 - acc: 0.7637\n",
      "Epoch 4/100\n",
      "3673/3673 [==============================] - 1s 146us/step - loss: 0.4980 - acc: 0.7650\n",
      "Epoch 5/100\n",
      "3673/3673 [==============================] - 1s 146us/step - loss: 0.4943 - acc: 0.7678\n",
      "Epoch 6/100\n",
      "3673/3673 [==============================] - 1s 147us/step - loss: 0.4918 - acc: 0.7697\n",
      "Epoch 7/100\n",
      "3673/3673 [==============================] - 1s 136us/step - loss: 0.4907 - acc: 0.7659\n",
      "Epoch 8/100\n",
      "3673/3673 [==============================] - 0s 135us/step - loss: 0.4883 - acc: 0.7680\n",
      "Epoch 9/100\n",
      "3673/3673 [==============================] - 1s 139us/step - loss: 0.4868 - acc: 0.7699\n",
      "Epoch 10/100\n",
      "3673/3673 [==============================] - 1s 141us/step - loss: 0.4852 - acc: 0.7689\n",
      "Epoch 11/100\n",
      "3673/3673 [==============================] - 1s 160us/step - loss: 0.4844 - acc: 0.7697\n",
      "Epoch 12/100\n",
      "3673/3673 [==============================] - 1s 198us/step - loss: 0.4828 - acc: 0.7710\n",
      "Epoch 13/100\n",
      "3673/3673 [==============================] - 1s 168us/step - loss: 0.4827 - acc: 0.7710\n",
      "Epoch 14/100\n",
      "3673/3673 [==============================] - 1s 197us/step - loss: 0.4820 - acc: 0.7713\n",
      "Epoch 15/100\n",
      "3673/3673 [==============================] - 1s 152us/step - loss: 0.4815 - acc: 0.7729\n",
      "Epoch 16/100\n",
      "3673/3673 [==============================] - 1s 138us/step - loss: 0.4813 - acc: 0.7699\n",
      "Epoch 17/100\n",
      "3673/3673 [==============================] - 0s 133us/step - loss: 0.4804 - acc: 0.7699\n",
      "Epoch 18/100\n",
      "3673/3673 [==============================] - 0s 117us/step - loss: 0.4794 - acc: 0.7691\n",
      "Epoch 19/100\n",
      "3673/3673 [==============================] - 0s 116us/step - loss: 0.4792 - acc: 0.7699\n",
      "Epoch 20/100\n",
      "3673/3673 [==============================] - 0s 109us/step - loss: 0.4788 - acc: 0.7724\n",
      "Epoch 21/100\n",
      "3673/3673 [==============================] - 0s 123us/step - loss: 0.4779 - acc: 0.7727\n",
      "Epoch 22/100\n",
      "3673/3673 [==============================] - 0s 128us/step - loss: 0.4781 - acc: 0.7735\n",
      "Epoch 23/100\n",
      "3673/3673 [==============================] - 0s 118us/step - loss: 0.4783 - acc: 0.7740\n",
      "Epoch 24/100\n",
      "3673/3673 [==============================] - 0s 127us/step - loss: 0.4775 - acc: 0.7735\n",
      "Epoch 25/100\n",
      "3673/3673 [==============================] - 0s 111us/step - loss: 0.4768 - acc: 0.7738\n",
      "Epoch 26/100\n",
      "3673/3673 [==============================] - 0s 107us/step - loss: 0.4760 - acc: 0.7732\n",
      "Epoch 27/100\n",
      "3673/3673 [==============================] - 0s 113us/step - loss: 0.4763 - acc: 0.7691\n",
      "Epoch 28/100\n",
      "3673/3673 [==============================] - 0s 118us/step - loss: 0.4759 - acc: 0.7732\n",
      "Epoch 29/100\n",
      "3673/3673 [==============================] - 0s 108us/step - loss: 0.4758 - acc: 0.7767\n",
      "Epoch 30/100\n",
      "3673/3673 [==============================] - 0s 119us/step - loss: 0.4752 - acc: 0.7735\n",
      "Epoch 31/100\n",
      "3673/3673 [==============================] - 0s 113us/step - loss: 0.4741 - acc: 0.7770\n",
      "Epoch 32/100\n",
      "3673/3673 [==============================] - 0s 108us/step - loss: 0.4747 - acc: 0.7740\n",
      "Epoch 33/100\n",
      "3673/3673 [==============================] - 0s 117us/step - loss: 0.4742 - acc: 0.7740\n",
      "Epoch 34/100\n",
      "3673/3673 [==============================] - 0s 131us/step - loss: 0.4742 - acc: 0.7740\n",
      "Epoch 35/100\n",
      "3673/3673 [==============================] - 0s 128us/step - loss: 0.4737 - acc: 0.7751\n",
      "Epoch 36/100\n",
      "3673/3673 [==============================] - 1s 184us/step - loss: 0.4739 - acc: 0.7795 0s - loss: 0.4720 - \n",
      "Epoch 37/100\n",
      "3673/3673 [==============================] - 0s 136us/step - loss: 0.4725 - acc: 0.7770\n",
      "Epoch 38/100\n",
      "3673/3673 [==============================] - 0s 116us/step - loss: 0.4717 - acc: 0.7773\n",
      "Epoch 39/100\n",
      "3673/3673 [==============================] - 1s 167us/step - loss: 0.4716 - acc: 0.7797\n",
      "Epoch 40/100\n",
      "3673/3673 [==============================] - 1s 225us/step - loss: 0.4707 - acc: 0.7765\n",
      "Epoch 41/100\n",
      "3673/3673 [==============================] - ETA: 0s - loss: 0.4720 - acc: 0.777 - 1s 149us/step - loss: 0.4697 - acc: 0.7800\n",
      "Epoch 42/100\n",
      "3673/3673 [==============================] - 1s 146us/step - loss: 0.4690 - acc: 0.7836\n",
      "Epoch 43/100\n",
      "3673/3673 [==============================] - 0s 133us/step - loss: 0.4685 - acc: 0.7803 0s - loss: 0.4847 - ac\n",
      "Epoch 44/100\n",
      "3673/3673 [==============================] - 1s 152us/step - loss: 0.4680 - acc: 0.7803\n",
      "Epoch 45/100\n",
      "3673/3673 [==============================] - 1s 136us/step - loss: 0.4685 - acc: 0.7816\n",
      "Epoch 46/100\n",
      "3673/3673 [==============================] - 1s 197us/step - loss: 0.4672 - acc: 0.7836\n",
      "Epoch 47/100\n",
      "3673/3673 [==============================] - 0s 124us/step - loss: 0.4672 - acc: 0.7825\n",
      "Epoch 48/100\n",
      "3673/3673 [==============================] - 0s 121us/step - loss: 0.4670 - acc: 0.7819\n",
      "Epoch 49/100\n",
      "3673/3673 [==============================] - 0s 128us/step - loss: 0.4659 - acc: 0.7819\n",
      "Epoch 50/100\n",
      "3673/3673 [==============================] - 1s 147us/step - loss: 0.4666 - acc: 0.7819\n",
      "Epoch 51/100\n",
      "3673/3673 [==============================] - 0s 128us/step - loss: 0.4653 - acc: 0.7825\n",
      "Epoch 52/100\n",
      "3673/3673 [==============================] - 0s 128us/step - loss: 0.4659 - acc: 0.7827\n",
      "Epoch 53/100\n",
      "3673/3673 [==============================] - 0s 120us/step - loss: 0.4656 - acc: 0.7860\n",
      "Epoch 54/100\n",
      "3673/3673 [==============================] - 0s 121us/step - loss: 0.4653 - acc: 0.7871\n",
      "Epoch 55/100\n",
      "3673/3673 [==============================] - 0s 121us/step - loss: 0.4648 - acc: 0.7852\n",
      "Epoch 56/100\n",
      "3673/3673 [==============================] - 0s 119us/step - loss: 0.4638 - acc: 0.7797\n",
      "Epoch 57/100\n",
      "3673/3673 [==============================] - 0s 121us/step - loss: 0.4640 - acc: 0.7827\n",
      "Epoch 58/100\n",
      "3673/3673 [==============================] - 0s 123us/step - loss: 0.4640 - acc: 0.7844\n",
      "Epoch 59/100\n",
      "3673/3673 [==============================] - 0s 131us/step - loss: 0.4639 - acc: 0.7860\n",
      "Epoch 60/100\n",
      "3673/3673 [==============================] - 0s 121us/step - loss: 0.4642 - acc: 0.7866\n",
      "Epoch 61/100\n",
      "3673/3673 [==============================] - 0s 117us/step - loss: 0.4632 - acc: 0.7846\n",
      "Epoch 62/100\n",
      "3673/3673 [==============================] - 0s 116us/step - loss: 0.4632 - acc: 0.7849\n",
      "Epoch 63/100\n",
      "3673/3673 [==============================] - 1s 161us/step - loss: 0.4630 - acc: 0.7868\n",
      "Epoch 64/100\n",
      "3673/3673 [==============================] - 1s 160us/step - loss: 0.4636 - acc: 0.7876\n",
      "Epoch 65/100\n",
      "3673/3673 [==============================] - 1s 149us/step - loss: 0.4630 - acc: 0.7871\n",
      "Epoch 66/100\n",
      "3673/3673 [==============================] - 1s 153us/step - loss: 0.4633 - acc: 0.7814\n",
      "Epoch 67/100\n",
      "3673/3673 [==============================] - 1s 138us/step - loss: 0.4628 - acc: 0.7830\n",
      "Epoch 68/100\n",
      "3673/3673 [==============================] - 0s 122us/step - loss: 0.4625 - acc: 0.7879\n",
      "Epoch 69/100\n",
      "3673/3673 [==============================] - 0s 124us/step - loss: 0.4619 - acc: 0.7874\n",
      "Epoch 70/100\n",
      "3673/3673 [==============================] - 0s 119us/step - loss: 0.4630 - acc: 0.7822\n",
      "Epoch 71/100\n",
      "3673/3673 [==============================] - 1s 170us/step - loss: 0.4623 - acc: 0.7868\n",
      "Epoch 72/100\n",
      "3673/3673 [==============================] - 0s 122us/step - loss: 0.4624 - acc: 0.7863\n",
      "Epoch 73/100\n",
      "3673/3673 [==============================] - 0s 108us/step - loss: 0.4612 - acc: 0.7833\n",
      "Epoch 74/100\n",
      "3673/3673 [==============================] - 0s 110us/step - loss: 0.4616 - acc: 0.7827\n",
      "Epoch 75/100\n",
      "3673/3673 [==============================] - 0s 107us/step - loss: 0.4619 - acc: 0.7874\n",
      "Epoch 76/100\n",
      "3673/3673 [==============================] - 0s 114us/step - loss: 0.4615 - acc: 0.7874\n",
      "Epoch 77/100\n",
      "3673/3673 [==============================] - 0s 118us/step - loss: 0.4610 - acc: 0.7860\n",
      "Epoch 78/100\n",
      "3673/3673 [==============================] - 1s 139us/step - loss: 0.4617 - acc: 0.7838\n",
      "Epoch 79/100\n",
      "3673/3673 [==============================] - 1s 181us/step - loss: 0.4607 - acc: 0.7860\n",
      "Epoch 80/100\n",
      "3673/3673 [==============================] - 1s 165us/step - loss: 0.4609 - acc: 0.7844\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3673/3673 [==============================] - 0s 126us/step - loss: 0.4604 - acc: 0.7822\n",
      "Epoch 82/100\n",
      "3673/3673 [==============================] - 0s 118us/step - loss: 0.4611 - acc: 0.7819\n",
      "Epoch 83/100\n",
      "3673/3673 [==============================] - 0s 124us/step - loss: 0.4610 - acc: 0.7857\n",
      "Epoch 84/100\n",
      "3673/3673 [==============================] - 1s 138us/step - loss: 0.4607 - acc: 0.7857\n",
      "Epoch 85/100\n",
      "3673/3673 [==============================] - 0s 123us/step - loss: 0.4610 - acc: 0.7830\n",
      "Epoch 86/100\n",
      "3673/3673 [==============================] - 0s 113us/step - loss: 0.4609 - acc: 0.7841\n",
      "Epoch 87/100\n",
      "3673/3673 [==============================] - 0s 118us/step - loss: 0.4610 - acc: 0.7844\n",
      "Epoch 88/100\n",
      "3673/3673 [==============================] - 0s 121us/step - loss: 0.4602 - acc: 0.7830\n",
      "Epoch 89/100\n",
      "3673/3673 [==============================] - 0s 133us/step - loss: 0.4592 - acc: 0.7816\n",
      "Epoch 90/100\n",
      "3673/3673 [==============================] - 0s 125us/step - loss: 0.4600 - acc: 0.7811\n",
      "Epoch 91/100\n",
      "3673/3673 [==============================] - 0s 121us/step - loss: 0.4598 - acc: 0.7860\n",
      "Epoch 92/100\n",
      "3673/3673 [==============================] - 0s 109us/step - loss: 0.4596 - acc: 0.7846\n",
      "Epoch 93/100\n",
      "3673/3673 [==============================] - 0s 110us/step - loss: 0.4606 - acc: 0.7849\n",
      "Epoch 94/100\n",
      "3673/3673 [==============================] - 0s 118us/step - loss: 0.4598 - acc: 0.7827\n",
      "Epoch 95/100\n",
      "3673/3673 [==============================] - 0s 131us/step - loss: 0.4600 - acc: 0.7863\n",
      "Epoch 96/100\n",
      "3673/3673 [==============================] - 0s 114us/step - loss: 0.4599 - acc: 0.7855\n",
      "Epoch 97/100\n",
      "3673/3673 [==============================] - 0s 130us/step - loss: 0.4595 - acc: 0.7874\n",
      "Epoch 98/100\n",
      "3673/3673 [==============================] - 0s 125us/step - loss: 0.4597 - acc: 0.7860\n",
      "Epoch 99/100\n",
      "3673/3673 [==============================] - 0s 116us/step - loss: 0.4588 - acc: 0.7836\n",
      "Epoch 100/100\n",
      "3673/3673 [==============================] - 0s 121us/step - loss: 0.4593 - acc: 0.7833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c813d9a358>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the model\n",
    "model = Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "model.add(Dense(output_dim = 8, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "\n",
    "# second hidden layer\n",
    "model.add(Dense(output_dim = 8, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the NN\n",
    "# binary_crossentropy loss function used when a binary output is expected\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "model.fit(x_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
