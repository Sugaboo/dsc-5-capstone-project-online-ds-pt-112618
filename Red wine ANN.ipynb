{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red wine ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold,cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequality-red.csv', low_memory=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the response variables(3-7) as binary response variables that is either good or bad\n",
    "\n",
    "names = ['bad', 'good']\n",
    "#bins = (2, 6.5, 8)\n",
    "\n",
    "#data['quality'] = pd.cut(data['quality'], bins = bins, labels = names)\n",
    "\n",
    "data['quality'] = data['quality'].map({3 : 'bad', 4 :'bad', 5: 'bad',\n",
    "                                      6: 'good', 7: 'good', 8: 'good'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good    855\n",
       "bad     744\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyzing the different values present in the dependent variable(quality column)\n",
    "data['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "5       0\n",
       "6       0\n",
       "7       1\n",
       "8       1\n",
       "9       0\n",
       "10      0\n",
       "11      0\n",
       "12      0\n",
       "13      0\n",
       "14      0\n",
       "15      0\n",
       "16      1\n",
       "17      0\n",
       "18      0\n",
       "19      1\n",
       "20      1\n",
       "21      0\n",
       "22      0\n",
       "23      0\n",
       "24      1\n",
       "25      0\n",
       "26      0\n",
       "27      0\n",
       "28      0\n",
       "29      1\n",
       "       ..\n",
       "1569    1\n",
       "1570    1\n",
       "1571    1\n",
       "1572    0\n",
       "1573    1\n",
       "1574    1\n",
       "1575    1\n",
       "1576    1\n",
       "1577    1\n",
       "1578    1\n",
       "1579    0\n",
       "1580    1\n",
       "1581    0\n",
       "1582    0\n",
       "1583    0\n",
       "1584    1\n",
       "1585    1\n",
       "1586    1\n",
       "1587    1\n",
       "1588    1\n",
       "1589    0\n",
       "1590    1\n",
       "1591    1\n",
       "1592    1\n",
       "1593    1\n",
       "1594    0\n",
       "1595    1\n",
       "1596    1\n",
       "1597    0\n",
       "1598    1\n",
       "Name: quality, Length: 1599, dtype: int32>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "data['quality'] = le.fit_transform(data['quality'])\n",
    "data['quality'].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25d7a8a6d68>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAASnElEQVR4nO3df5Bd5X3f8ffHCIztGosfC8WSWpFaceJpa4x3XGqPU9dKOoYkFkkhg6cxGqoZpR2aJk5/hLYztdumM/bUDTWelI5qbAuPi01wCIqHSUtlUydxIVmwChjqYUMI2kqR1uaHfzAkUfLtH/fZh0W6ki6gs7to36+ZO+ec73nOvV/NCD56zrn3nFQVkiQBvGK5G5AkrRyGgiSpMxQkSZ2hIEnqDAVJUrdmuRt4Kc4555zauHHjcrchSS8r99577zeramrcvpd1KGzcuJGZmZnlbkOSXlaS/OHR9nn6SJLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktS9rH/RLJ3MHv+3f225W9AK9Jf+9QODvr8zBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVI3aCgk+UCSryd5MMnNSU5PckGSe5I8kuTzSU5rY1/Ztmfb/o1D9iZJOtJgoZBkHfCPgemq+qvAKcCVwEeA66pqE/AksK0dsg14sqreAFzXxkmSltDQp4/WAK9KsgZ4NbAfeDdwa9u/E7isrW9p27T9m5Nk4P4kSYsMFgpV9f+AjwKPMwqDp4F7gaeq6lAbNgesa+vrgL3t2ENt/NmHv2+S7UlmkszMz88P1b4krUpDnj46k9G//i8AXg+8BrhkzNBaOOQY+54rVO2oqumqmp6amjpR7UqSGPb00Q8Df1BV81X1p8CvAW8H1rbTSQDrgX1tfQ7YAND2vw54YsD+JEmHGTIUHgcuTvLqdm1gM/AQ8GXg8jZmK3B7W9/Vtmn7v1RVR8wUJEnDGfKawj2MLhjfBzzQPmsH8IvALySZZXTN4MZ2yI3A2a3+C8C1Q/UmSRpv0CevVdUHgQ8eVn4UeNuYsc8CVwzZjyTp2PxFsySpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYP+eO3l4K3/7KblbkEr0L3/4arlbkFaFs4UJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkbshnNL8xyZ5Fr28n+fkkZyW5M8kjbXlmG58k1yeZTXJ/kouG6k2SNN6QT177RlVdWFUXAm8FngFuY/REtd1VtQnYzXNPWLsE2NRe24EbhupNkjTeUp0+2gz8flX9IbAF2NnqO4HL2voW4KYauRtYm+T8JepPksTShcKVwM1t/byq2g/Qlue2+jpg76Jj5lrteZJsTzKTZGZ+fn7AliVp9Rk8FJKcBrwX+NXjDR1TqyMKVTuqarqqpqempk5Ei5KkZilmCpcA91XVgbZ9YOG0UFsebPU5YMOi49YD+5agP0lSsxSh8D6eO3UEsAvY2ta3Arcvql/VvoV0MfD0wmkmSdLSGPQuqUleDfwI8DOLyh8GbkmyDXgcuKLV7wAuBWYZfVPp6iF7kyQdadBQqKpngLMPq32L0beRDh9bwDVD9iNJOjZ/0SxJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkbNBSSrE1ya5L/m+ThJH8zyVlJ7kzySFue2cYmyfVJZpPcn+SiIXuTJB1p6JnCx4DfrKofAN4MPAxcC+yuqk3A7rYNo2c5b2qv7cANA/cmSTrMYKGQ5Azgh4AbAarqT6rqKWALsLMN2wlc1ta3ADfVyN3A2iTnD9WfJOlIQ84Uvg+YBz6V5GtJPpHkNcB5VbUfoC3PbePXAXsXHT/Xas+TZHuSmSQz8/PzA7YvSavPkKGwBrgIuKGq3gJ8j+dOFY2TMbU6olC1o6qmq2p6amrqxHQqSQKGDYU5YK6q7mnbtzIKiQMLp4Xa8uCi8RsWHb8e2Ddgf5KkwwwWClX1R8DeJG9spc3AQ8AuYGurbQVub+u7gKvat5AuBp5eOM0kSVoaawZ+/58FPpvkNOBR4GpGQXRLkm3A48AVbewdwKXALPBMGytJWkKDhkJV7QGmx+zaPGZsAdcM2Y8k6dj8RbMkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYOGQpLHkjyQZE+SmVY7K8mdSR5pyzNbPUmuTzKb5P4kFw3ZmyTpSEsxU/jbVXVhVS08ge1aYHdVbQJ2t22AS4BN7bUduGEJepMkLbIcp4+2ADvb+k7gskX1m2rkbmBtkvOXoT9JWrWGDoUC/keSe5Nsb7Xzqmo/QFue2+rrgL2Ljp1rtedJsj3JTJKZ+fn5AVuXpNVnolBIsnuS2hjvqKqLGJ0auibJDx3rY8bU6ohC1Y6qmq6q6ampqQlakCRNas2xdiY5HXg1cE67ILzwP+4zgNcf782ral9bHkxyG/A24ECS86tqfzs9dLANnwM2LDp8PbDvhfxhJEkvzfFmCj8D3Av8QFsuvG4HfuVYByZ5TZLXLqwDfwd4ENgFbG3Dtrb3otWvat9Cuhh4euE0kyRpaRxzplBVHwM+luRnq+rjL/C9zwNuS7LwOf+tqn4zye8BtyTZBjwOXNHG3wFcCswCzwBXv8DPkyS9RMcMhQVV9fEkbwc2Lj6mqm46xjGPAm8eU/8WsHlMvYBrJulHkjSMiUIhyWeAvwLsAf6slQs4aihIkl5+JgoFYBp4U/vXvCTpJDXp7xQeBP7ikI1IkpbfpDOFc4CHkvwu8McLxap67yBdSZKWxaSh8KEhm5AkrQyTfvvofw3diCRp+U367aPv8NwtJ04DTgW+V1VnDNWYJGnpTTpTeO3i7SSXMbplhSTpJPKi7pJaVb8OvPsE9yJJWmaTnj76yUWbr2D0uwV/syBJJ5lJv33044vWDwGPMXoojiTpJDLpNQVvTidJq8CkD9lZn+S2JAeTHEjyhSTrh25OkrS0Jr3Q/ClGzzt4PaNHZP5Gq0mSTiKThsJUVX2qqg6116cBn4UpSSeZSUPhm0l+Oskp7fXTwLcmObCN/1qSL7btC5Lck+SRJJ9Pclqrv7Jtz7b9G1/MH0iS9OJNGgp/H/gp4I+A/cDlTP5ktJ8DHl60/RHguqraBDwJbGv1bcCTVfUG4Lo2TpK0hCYNhX8HbK2qqao6l1FIfOh4B7WL0T8KfKJth9GP3m5tQ3YCl7X1LW2btn9zGy9JWiKThsJfr6onFzaq6gngLRMc95+Afw78eds+G3iqqg617TlGF65py73t/Q8BT7fxz5Nke5KZJDPz8/MTti9JmsSkofCKJGcubCQ5i+P8xiHJjwEHq+rexeUxQ2uCfc8VqnZU1XRVTU9Nea1bkk6kSX/R/B+Brya5ldH/qH8K+PfHOeYdwHuTXAqcDpzBaOawNsmaNhtYD+xr4+eADcBckjXA64AnXsgfRpL00kw0U6iqm4C/CxwA5oGfrKrPHOeYf1FV66tqI3Al8KWq+nvAlxldqAbYCtze1ne1bdr+L/lMaElaWpPOFKiqh4CHTsBn/iLwuSS/BHwNuLHVbwQ+k2SW0QzhyhPwWZKkF2DiUHgpquou4K62/ihjnsVQVc8CVyxFP5Kk8V7U8xQkSScnQ0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gYLhSSnJ/ndJP8nydeT/JtWvyDJPUkeSfL5JKe1+ivb9mzbv3Go3iRJ4w05U/hj4N1V9WbgQuA9SS4GPgJcV1WbgCeBbW38NuDJqnoDcF0bJ0laQoOFQo18t22e2l4FvBu4tdV3Ape19S1tm7Z/c5IM1Z8k6UiDXlNIckqSPcBB4E7g94GnqupQGzIHrGvr64C9AG3/08DZY95ze5KZJDPz8/NDti9Jq86goVBVf1ZVFwLrGT2X+QfHDWvLcbOCOqJQtaOqpqtqempq6sQ1K0lamm8fVdVTwF3AxcDaJGvarvXAvrY+B2wAaPtfBzyxFP1JkkaG/PbRVJK1bf1VwA8DDwNfBi5vw7YCt7f1XW2btv9LVXXETEGSNJw1xx/yop0P7ExyCqPwuaWqvpjkIeBzSX4J+BpwYxt/I/CZJLOMZghXDtibJGmMwUKhqu4H3jKm/iij6wuH158FrhiqH0nS8fmLZklSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSd2QT17bkOTLSR5O8vUkP9fqZyW5M8kjbXlmqyfJ9Ulmk9yf5KKhepMkjTfkTOEQ8E+q6gcZPZv5miRvAq4FdlfVJmB32wa4BNjUXtuBGwbsTZI0xmChUFX7q+q+tv4dRs9nXgdsAXa2YTuBy9r6FuCmGrkbWJvk/KH6kyQdaUmuKSTZyOjRnPcA51XVfhgFB3BuG7YO2LvosLlWO/y9tieZSTIzPz8/ZNuStOoMHgpJ/gLwBeDnq+rbxxo6plZHFKp2VNV0VU1PTU2dqDYlSQwcCklOZRQIn62qX2vlAwunhdryYKvPARsWHb4e2Ddkf5Kk5xvy20cBbgQerqpfXrRrF7C1rW8Fbl9Uv6p9C+li4OmF00ySpKWxZsD3fgfwfuCBJHta7V8CHwZuSbINeBy4ou27A7gUmAWeAa4esDdJ0hiDhUJV/TbjrxMAbB4zvoBrhupHknR8/qJZktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSN+ST1z6Z5GCSBxfVzkpyZ5JH2vLMVk+S65PMJrk/yUVD9SVJOrohZwqfBt5zWO1aYHdVbQJ2t22AS4BN7bUduGHAviRJRzFYKFTVV4AnDitvAXa29Z3AZYvqN9XI3cDaJOcP1ZskabylvqZwXlXtB2jLc1t9HbB30bi5VpMkLaGVcqF53LOca+zAZHuSmSQz8/PzA7clSavLUofCgYXTQm15sNXngA2Lxq0H9o17g6raUVXTVTU9NTU1aLOStNosdSjsAra29a3A7YvqV7VvIV0MPL1wmkmStHTWDPXGSW4G3gWck2QO+CDwYeCWJNuAx4Er2vA7gEuBWeAZ4Oqh+pIkHd1goVBV7zvKrs1jxhZwzVC9SJIms1IuNEuSVgBDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUreiQiHJe5J8I8lskmuXux9JWm1WTCgkOQX4FeAS4E3A+5K8aXm7kqTVZcWEAvA2YLaqHq2qPwE+B2xZ5p4kaVUZ7BnNL8I6YO+i7Tngbxw+KMl2YHvb/G6SbyxBb6vFOcA3l7uJlSAf3brcLej5/Lu54IM5Ee/yl4+2YyWFwrg/aR1RqNoB7Bi+ndUnyUxVTS93H9Lh/Lu5dFbS6aM5YMOi7fXAvmXqRZJWpZUUCr8HbEpyQZLTgCuBXcvckyStKivm9FFVHUryj4D/DpwCfLKqvr7Mba02npbTSuXfzSWSqiNO20uSVqmVdPpIkrTMDAVJUmcoyNuLaMVK8skkB5M8uNy9rBaGwirn7UW0wn0aeM9yN7GaGAry9iJasarqK8ATy93HamIoaNztRdYtUy+SlpmhoIluLyJpdTAU5O1FJHWGgry9iKTOUFjlquoQsHB7kYeBW7y9iFaKJDcD/xt4Y5K5JNuWu6eTnbe5kCR1zhQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkK0oCSbFy4w2eS6STXt/V3JXn78nYnHWnFPI5TOtlV1Qww0zbfBXwX+OqyNSSN4UxBOook/6o9Z+J/Jrk5yT9NcleS6bb/nCSPtfWNSX4ryX3tdcQsoM0OvphkI/APgA8k2ZPknUn+IMmpbdwZSR5b2JaWkjMFaYwkb2V0y4+3MPrv5D7g3mMcchD4kap6Nskm4GZgetzAqnosyX8BvltVH22fdxfwo8Cvt8/9QlX96Qn640gTc6YgjfdO4Laqeqaqvs3x7wd1KvBfkzwA/CqjBxa9EJ8Arm7rVwOfeoHHSyeEMwXp6MbdA+YQz/1j6vRF9Q8AB4A3t/3PvqAPqvqddgrqbwGnVJWPn9SycKYgjfcV4CeSvCrJa4Efb/XHgLe29csXjX8dsL+q/hx4P3DKcd7/O8BrD6vdxOi0k7MELRtDQRqjqu4DPg/sAb4A/Fbb9VHgHyb5KnDOokP+M7A1yd3A9wPfO85H/Aaj0NmT5J2t9lngTEbBIC0L75IqTSDJh1h0YXigz7gc2FJV7x/qM6Tj8ZqCtAIk+ThwCXDpcvei1c2ZgiSp85qCJKkzFCRJnaEgSeoMBUlSZyhIkrr/D1N83AVGpNkUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 11)\n",
      "(1599,)\n"
     ]
    }
   ],
   "source": [
    "# dividing the dataset into dependent and independent variables\n",
    "\n",
    "x = data.iloc[:,:11]\n",
    "y = data.iloc[:,11]\n",
    "\n",
    "# determining the shape of x and y.\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1199, 11)\n",
      "(1199,)\n",
      "(400, 11)\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "# dividing the dataset in training and testing set\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 44)\n",
    "\n",
    "# determining the shapes of training and testing sets\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaling \n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy : 0.9332777314428691\n",
      "testing accuracy : 0.7425\n"
     ]
    }
   ],
   "source": [
    "# creating the model\n",
    "model = MLPClassifier(hidden_layer_sizes = (100, 100), max_iter = 150)\n",
    "\n",
    "# feeding the training data to the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# calculating the accuracies\n",
    "print(\"training accuracy :\", model.score(x_train, y_train))\n",
    "print(\"testing accuracy :\", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 177\n",
      "Trainable params: 177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0825 01:40:25.279289 17980 deprecation_wrapper.py:119] From C:\\Users\\lasha\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0825 01:40:25.356053 17980 deprecation_wrapper.py:119] From C:\\Users\\lasha\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0825 01:40:25.378997 17980 deprecation_wrapper.py:119] From C:\\Users\\lasha\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0825 01:40:25.464763 17980 deprecation_wrapper.py:119] From C:\\Users\\lasha\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0825 01:40:25.506658 17980 deprecation_wrapper.py:119] From C:\\Users\\lasha\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0825 01:40:25.517622 17980 deprecation.py:323] From C:\\Users\\lasha\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0825 01:40:25.755324 17980 deprecation_wrapper.py:119] From C:\\Users\\lasha\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1199/1199 [==============================] - 1s 570us/step - loss: 0.6841 - acc: 0.5505\n",
      "Epoch 2/100\n",
      "1199/1199 [==============================] - 0s 142us/step - loss: 0.5999 - acc: 0.7098\n",
      "Epoch 3/100\n",
      "1199/1199 [==============================] - 0s 138us/step - loss: 0.5395 - acc: 0.7481\n",
      "Epoch 4/100\n",
      "1199/1199 [==============================] - 0s 142us/step - loss: 0.5178 - acc: 0.7473\n",
      "Epoch 5/100\n",
      "1199/1199 [==============================] - 0s 274us/step - loss: 0.5108 - acc: 0.7490\n",
      "Epoch 6/100\n",
      "1199/1199 [==============================] - 0s 210us/step - loss: 0.5080 - acc: 0.7523\n",
      "Epoch 7/100\n",
      "1199/1199 [==============================] - 0s 148us/step - loss: 0.5066 - acc: 0.7531\n",
      "Epoch 8/100\n",
      "1199/1199 [==============================] - 0s 159us/step - loss: 0.5054 - acc: 0.7531\n",
      "Epoch 9/100\n",
      "1199/1199 [==============================] - 0s 255us/step - loss: 0.5044 - acc: 0.7573\n",
      "Epoch 10/100\n",
      "1199/1199 [==============================] - 0s 215us/step - loss: 0.5036 - acc: 0.7531\n",
      "Epoch 11/100\n",
      "1199/1199 [==============================] - 0s 150us/step - loss: 0.5028 - acc: 0.7598\n",
      "Epoch 12/100\n",
      "1199/1199 [==============================] - 0s 171us/step - loss: 0.5023 - acc: 0.7573\n",
      "Epoch 13/100\n",
      "1199/1199 [==============================] - 0s 151us/step - loss: 0.5020 - acc: 0.7581\n",
      "Epoch 14/100\n",
      "1199/1199 [==============================] - 0s 158us/step - loss: 0.5014 - acc: 0.7556\n",
      "Epoch 15/100\n",
      "1199/1199 [==============================] - 0s 299us/step - loss: 0.5009 - acc: 0.7565\n",
      "Epoch 16/100\n",
      "1199/1199 [==============================] - 0s 143us/step - loss: 0.5003 - acc: 0.7615\n",
      "Epoch 17/100\n",
      "1199/1199 [==============================] - 0s 141us/step - loss: 0.5006 - acc: 0.7606\n",
      "Epoch 18/100\n",
      "1199/1199 [==============================] - 0s 146us/step - loss: 0.4989 - acc: 0.7631\n",
      "Epoch 19/100\n",
      "1199/1199 [==============================] - 0s 150us/step - loss: 0.4981 - acc: 0.7590\n",
      "Epoch 20/100\n",
      "1199/1199 [==============================] - 0s 245us/step - loss: 0.4981 - acc: 0.7631\n",
      "Epoch 21/100\n",
      "1199/1199 [==============================] - 0s 260us/step - loss: 0.4973 - acc: 0.7631\n",
      "Epoch 22/100\n",
      "1199/1199 [==============================] - 0s 251us/step - loss: 0.4969 - acc: 0.7631\n",
      "Epoch 23/100\n",
      "1199/1199 [==============================] - 0s 235us/step - loss: 0.4961 - acc: 0.7648\n",
      "Epoch 24/100\n",
      "1199/1199 [==============================] - 0s 166us/step - loss: 0.4965 - acc: 0.7656\n",
      "Epoch 25/100\n",
      "1199/1199 [==============================] - 0s 152us/step - loss: 0.4952 - acc: 0.7665\n",
      "Epoch 26/100\n",
      "1199/1199 [==============================] - 0s 182us/step - loss: 0.4944 - acc: 0.7631\n",
      "Epoch 27/100\n",
      "1199/1199 [==============================] - 0s 148us/step - loss: 0.4939 - acc: 0.7640\n",
      "Epoch 28/100\n",
      "1199/1199 [==============================] - 0s 158us/step - loss: 0.4940 - acc: 0.7656\n",
      "Epoch 29/100\n",
      "1199/1199 [==============================] - 0s 162us/step - loss: 0.4922 - acc: 0.7690\n",
      "Epoch 30/100\n",
      "1199/1199 [==============================] - 0s 166us/step - loss: 0.4914 - acc: 0.7681\n",
      "Epoch 31/100\n",
      "1199/1199 [==============================] - 0s 157us/step - loss: 0.4911 - acc: 0.7698\n",
      "Epoch 32/100\n",
      "1199/1199 [==============================] - 0s 162us/step - loss: 0.4903 - acc: 0.7698\n",
      "Epoch 33/100\n",
      "1199/1199 [==============================] - 0s 158us/step - loss: 0.4891 - acc: 0.7673\n",
      "Epoch 34/100\n",
      "1199/1199 [==============================] - 0s 171us/step - loss: 0.4880 - acc: 0.7690\n",
      "Epoch 35/100\n",
      "1199/1199 [==============================] - 0s 145us/step - loss: 0.4875 - acc: 0.7731\n",
      "Epoch 36/100\n",
      "1199/1199 [==============================] - 0s 143us/step - loss: 0.4866 - acc: 0.7648\n",
      "Epoch 37/100\n",
      "1199/1199 [==============================] - 0s 141us/step - loss: 0.4851 - acc: 0.7715\n",
      "Epoch 38/100\n",
      "1199/1199 [==============================] - 0s 154us/step - loss: 0.4842 - acc: 0.7656\n",
      "Epoch 39/100\n",
      "1199/1199 [==============================] - 0s 148us/step - loss: 0.4829 - acc: 0.7698\n",
      "Epoch 40/100\n",
      "1199/1199 [==============================] - 0s 171us/step - loss: 0.4827 - acc: 0.7765\n",
      "Epoch 41/100\n",
      "1199/1199 [==============================] - 0s 151us/step - loss: 0.4810 - acc: 0.7648\n",
      "Epoch 42/100\n",
      "1199/1199 [==============================] - 0s 192us/step - loss: 0.4805 - acc: 0.7723\n",
      "Epoch 43/100\n",
      "1199/1199 [==============================] - 0s 189us/step - loss: 0.4801 - acc: 0.7723\n",
      "Epoch 44/100\n",
      "1199/1199 [==============================] - 0s 177us/step - loss: 0.4783 - acc: 0.7698\n",
      "Epoch 45/100\n",
      "1199/1199 [==============================] - 0s 157us/step - loss: 0.4779 - acc: 0.7723\n",
      "Epoch 46/100\n",
      "1199/1199 [==============================] - 0s 169us/step - loss: 0.4778 - acc: 0.7698\n",
      "Epoch 47/100\n",
      "1199/1199 [==============================] - 0s 148us/step - loss: 0.4773 - acc: 0.7690\n",
      "Epoch 48/100\n",
      "1199/1199 [==============================] - 0s 162us/step - loss: 0.4757 - acc: 0.7731\n",
      "Epoch 49/100\n",
      "1199/1199 [==============================] - 0s 179us/step - loss: 0.4755 - acc: 0.7706\n",
      "Epoch 50/100\n",
      "1199/1199 [==============================] - 0s 210us/step - loss: 0.4748 - acc: 0.7740\n",
      "Epoch 51/100\n",
      "1199/1199 [==============================] - 0s 183us/step - loss: 0.4739 - acc: 0.7740\n",
      "Epoch 52/100\n",
      "1199/1199 [==============================] - 0s 234us/step - loss: 0.4736 - acc: 0.7765\n",
      "Epoch 53/100\n",
      "1199/1199 [==============================] - 0s 267us/step - loss: 0.4729 - acc: 0.7773\n",
      "Epoch 54/100\n",
      "1199/1199 [==============================] - 0s 349us/step - loss: 0.4729 - acc: 0.7807\n",
      "Epoch 55/100\n",
      "1199/1199 [==============================] - 0s 265us/step - loss: 0.4717 - acc: 0.7781\n",
      "Epoch 56/100\n",
      "1199/1199 [==============================] - 0s 225us/step - loss: 0.4718 - acc: 0.7748\n",
      "Epoch 57/100\n",
      "1199/1199 [==============================] - 0s 195us/step - loss: 0.4707 - acc: 0.7815\n",
      "Epoch 58/100\n",
      "1199/1199 [==============================] - 0s 286us/step - loss: 0.4702 - acc: 0.7823\n",
      "Epoch 59/100\n",
      "1199/1199 [==============================] - 0s 230us/step - loss: 0.4697 - acc: 0.7815 0s - loss: 0.4120 - acc: 0\n",
      "Epoch 60/100\n",
      "1199/1199 [==============================] - 0s 240us/step - loss: 0.4696 - acc: 0.7790\n",
      "Epoch 61/100\n",
      "1199/1199 [==============================] - 0s 238us/step - loss: 0.4691 - acc: 0.7848\n",
      "Epoch 62/100\n",
      "1199/1199 [==============================] - 0s 262us/step - loss: 0.4691 - acc: 0.7857\n",
      "Epoch 63/100\n",
      "1199/1199 [==============================] - 0s 259us/step - loss: 0.4687 - acc: 0.7898\n",
      "Epoch 64/100\n",
      "1199/1199 [==============================] - 0s 285us/step - loss: 0.4683 - acc: 0.7848\n",
      "Epoch 65/100\n",
      "1199/1199 [==============================] - 0s 321us/step - loss: 0.4675 - acc: 0.7873\n",
      "Epoch 66/100\n",
      "1199/1199 [==============================] - 0s 304us/step - loss: 0.4681 - acc: 0.7798\n",
      "Epoch 67/100\n",
      "1199/1199 [==============================] - 0s 284us/step - loss: 0.4672 - acc: 0.7882\n",
      "Epoch 68/100\n",
      "1199/1199 [==============================] - 0s 233us/step - loss: 0.4674 - acc: 0.7865\n",
      "Epoch 69/100\n",
      "1199/1199 [==============================] - 0s 223us/step - loss: 0.4662 - acc: 0.7882\n",
      "Epoch 70/100\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.4761 - acc: 0.784 - 0s 240us/step - loss: 0.4673 - acc: 0.7882\n",
      "Epoch 71/100\n",
      "1199/1199 [==============================] - 0s 210us/step - loss: 0.4667 - acc: 0.7882\n",
      "Epoch 72/100\n",
      "1199/1199 [==============================] - 0s 159us/step - loss: 0.4660 - acc: 0.7907\n",
      "Epoch 73/100\n",
      "1199/1199 [==============================] - 0s 151us/step - loss: 0.4666 - acc: 0.7898\n",
      "Epoch 74/100\n",
      "1199/1199 [==============================] - 0s 162us/step - loss: 0.4651 - acc: 0.7898\n",
      "Epoch 75/100\n",
      "1199/1199 [==============================] - 0s 190us/step - loss: 0.4646 - acc: 0.7915\n",
      "Epoch 76/100\n",
      "1199/1199 [==============================] - 0s 168us/step - loss: 0.4648 - acc: 0.7890\n",
      "Epoch 77/100\n",
      "1199/1199 [==============================] - 0s 216us/step - loss: 0.4643 - acc: 0.7907\n",
      "Epoch 78/100\n",
      "1199/1199 [==============================] - 0s 192us/step - loss: 0.4641 - acc: 0.7940\n",
      "Epoch 79/100\n",
      "1199/1199 [==============================] - 0s 169us/step - loss: 0.4646 - acc: 0.7898\n",
      "Epoch 80/100\n",
      "1199/1199 [==============================] - 0s 159us/step - loss: 0.4637 - acc: 0.7907\n",
      "Epoch 81/100\n",
      "1199/1199 [==============================] - 0s 190us/step - loss: 0.4629 - acc: 0.7915\n",
      "Epoch 82/100\n",
      "1199/1199 [==============================] - 0s 155us/step - loss: 0.4636 - acc: 0.7857\n",
      "Epoch 83/100\n",
      "1199/1199 [==============================] - 0s 180us/step - loss: 0.4626 - acc: 0.7948\n",
      "Epoch 84/100\n",
      "1199/1199 [==============================] - 0s 190us/step - loss: 0.4627 - acc: 0.7915\n",
      "Epoch 85/100\n",
      "1199/1199 [==============================] - 0s 192us/step - loss: 0.4627 - acc: 0.7915\n",
      "Epoch 86/100\n",
      "1199/1199 [==============================] - 0s 230us/step - loss: 0.4624 - acc: 0.7932 0s - loss: 0.4421 - acc: 0.\n",
      "Epoch 87/100\n",
      "1199/1199 [==============================] - 0s 281us/step - loss: 0.4615 - acc: 0.7915\n",
      "Epoch 88/100\n",
      "1199/1199 [==============================] - 0s 225us/step - loss: 0.4616 - acc: 0.7907\n",
      "Epoch 89/100\n",
      "1199/1199 [==============================] - 0s 280us/step - loss: 0.4612 - acc: 0.7923\n",
      "Epoch 90/100\n",
      "1199/1199 [==============================] - 0s 245us/step - loss: 0.4609 - acc: 0.7915\n",
      "Epoch 91/100\n",
      "1199/1199 [==============================] - 0s 250us/step - loss: 0.4615 - acc: 0.7948\n",
      "Epoch 92/100\n",
      "1199/1199 [==============================] - 0s 250us/step - loss: 0.4608 - acc: 0.7932\n",
      "Epoch 93/100\n",
      "1199/1199 [==============================] - ETA: 0s - loss: 0.4595 - acc: 0.796 - 0s 195us/step - loss: 0.4596 - acc: 0.7932\n",
      "Epoch 94/100\n",
      "1199/1199 [==============================] - 0s 170us/step - loss: 0.4594 - acc: 0.7965\n",
      "Epoch 95/100\n",
      "1199/1199 [==============================] - 0s 249us/step - loss: 0.4599 - acc: 0.7898\n",
      "Epoch 96/100\n",
      "1199/1199 [==============================] - 0s 265us/step - loss: 0.4590 - acc: 0.7948\n",
      "Epoch 97/100\n",
      "1199/1199 [==============================] - 0s 246us/step - loss: 0.4590 - acc: 0.7907\n",
      "Epoch 98/100\n",
      "1199/1199 [==============================] - 0s 243us/step - loss: 0.4590 - acc: 0.7948\n",
      "Epoch 99/100\n",
      "1199/1199 [==============================] - 0s 240us/step - loss: 0.4581 - acc: 0.7873\n",
      "Epoch 100/100\n",
      "1199/1199 [==============================] - 0s 255us/step - loss: 0.4582 - acc: 0.7915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d7a96c470>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the model\n",
    "model = Sequential()\n",
    "\n",
    "# first hidden layer\n",
    "model.add(Dense(output_dim = 8, init = 'uniform', activation = 'relu', input_dim = 11))\n",
    "\n",
    "# second hidden layer\n",
    "model.add(Dense(output_dim = 8, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the NN\n",
    "# binary_crossentropy loss function used when a binary output is expected\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "model.fit(x_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
